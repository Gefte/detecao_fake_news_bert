# detecao_fake_news_bert
### Detecção de Fake News usando Bag-of-Words, Word2Vec e  BERT.
Nesse projeto é feita uma análise da eficiência dos principais modelo de "Word Embedding", para a detecção de noticias falsas. 

O uso de  modelos de  codificação de texto para  numero denomina <i>"Word Embedding"</i>, uma parte essencial na engenharia de features para um modelo de NLP.
A estátistica <a href=https://medium.com/@fonsecamilla>Camila Fonseca</a> no texto <a href=https://medium.com/turing-talks/introdu%C3%A7%C3%A3o-a-bag-of-words-e-tf-idf-43a128151ce9> "Introdução a Bag Of Words e TF-IDF</a> em seu blog no <a href=https://medium.com/>Medium</a> explica com mais detalhes o porque usar <i>Word embedings</i>:

 <i>Para usarmos um modelo estatístico ou de deep learning em NLP, precisamos de features: informações mensuráveis acerca de algum fenômeno, ou seja, uma forma estruturada de armazenar informações. Porém, textos são um tipo de dado não estruturado (não organizado de uma maneira pré-definida, fixa), assim, é difícil para o computador entendê-los e analisá-los. Por isso, realizamos a chamada feature extraction, ou seja, transformamos o texto em uma informação numérica de modo que seja possível utilizá-lo para alimentar um modelo.</i>






 Fontes:

 https://medium.com/turing-talks/word-embedding-fazendo-o-computador-entender-o-significado-das-palavras-92fe22745057
 
 https://medium.com/turing-talks/introdu%C3%A7%C3%A3o-a-bag-of-words-e-tf-idf-43a128151ce9

https://repositorio.unesp.br/handle/11449/234317

https://github.com/Gabriel-Lino-Garcia/FakeRecogna

https://www.youtube.com/watch?v=W7aORTUCAqQ&t=577s&ab_channel=UniversoDiscreto

https://sol.sbc.org.br/index.php/stil/article/view/17784

https://huggingface.co/neuralmind/bert-base-portuguese-cased

http://www.nilc.icmc.usp.br/embeddings